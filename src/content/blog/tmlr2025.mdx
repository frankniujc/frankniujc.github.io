---
author: Jingcheng Niu
date: 2025-09-09
title: "Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning"
slug: tmlr2025
featured: false
draft: false
venue: TMLR 2025
paper: https://arxiv.org/abs/2505.11004/
paper_linkname: arXiv
code: https://github.com/UKPLab/arxiv2025-icl-investigation/

authors:
  - Jingcheng Niu
  - Subhabrata Dutta
  - Ahmed Elshabrawy
  - Harish Tayyar Madabushi
  - Iryna Gurevych

tags:
  - interpretability
  - ICL
  - induction head
---

<div class="not-prose" style="margin:0.25rem 0; padding:0; text-align:center; display:flex; gap:0.5rem; justify-content:center; align-items:center; flex-wrap:nowrap; white-space:nowrap;">
  <a href="https://arxiv.org/abs/2505.11004" style="display:inline-flex; align-items:center; text-decoration:none !important; border-bottom:none; outline:none;">
    <img src="https://img.shields.io/badge/arXiv-2505.11004-b31b1b?style=flat&logo=arxiv" alt="Arxiv" />
  </a>
  <a href="https://arxiv.org/abs/2505.11004" style="display:inline-flex; align-items:center; text-decoration:none !important; border-bottom:none; outline:none;">
    <img src="https://img.shields.io/badge/Code-ICL Investigation-181717?style=flat&logo=github" alt="Arxiv" />
  </a>
</div>

Have you ever wondered why LLMs are able to perform in-context learning (ICL)?

<img src="/research/tmlr2025/open_fig.svg" alt="Open Figure" />

Right now, there are two main hypotheses to explain ICL:
- **Memorization Hypothesis**: LLMs memorise a vast amount of data during pre=training, and ICL is an illusion created by this memorization.
- **Mechanistic Algorithm Hypothesis**: LLMs have developed internal mechanisms that follow specific algorithms to perform ICL.

There's also a debate regarding *how* this ICL ability appear in LLMs during pre-training. 

## Finding 1: ICL is neither an illusion of memorization, nor the development of an internal symbolic algorithm. It's still built on token statistics.


## Finding 2: ICL is neither an illusion of memorization, nor the development of an internal symbolic algorithm. It's still built on token statistics.


## Finding 1: ICL is neither an illusion of memorization, nor the development of an internal symbolic algorithm. It's still built on token statistics.

## How to Cite 

```bibtex
@misc{niu2025illusionalgorithminvestigatingmemorization,
      title={Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning}, 
      author={Jingcheng Niu and
        Subhabrata Dutta and
        Ahmed Elshabrawy and
        Harish Tayyar Madabushi and
        Iryna Gurevych},
      year={2025},
      eprint={2505.11004},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.11004}, 
}
```